{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90b7ecb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import col, lit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d21cf43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"SparkExamples.com\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d7ab266",
   "metadata": {},
   "outputs": [],
   "source": [
    "#before this please create a dataset in Azure and start you ADF directory and save the data to local \n",
    "df = spark.read.format(\"csv\").option(\"header\",True).load(\"file:///D:/data1/personal_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fab7837c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------+--------+---+----------+----------+----------+------------+--------------------+------+------+\n",
      "| SN|firstname|middlename|lastname|age|experiance|     skill|      city|departmentID|                 DOB|gender|salary|\n",
      "+---+---------+----------+--------+---+----------+----------+----------+------------+--------------------+------+------+\n",
      "|  1|    James|        Kc|   Smith| 51|        10|      .Net|   Newyork|           1|1991-04-01 00:00:...|     M|  3000|\n",
      "|  2|  Michael|      Rose|    None| 45|        11|      Ruby|   Newyork|           2|2000-05-19 00:00:...|     M|  4000|\n",
      "|  3|   Robert|      None|Williams| 32|        10|     Scala|California|           1|1978-09-05 00:00:...|     M|  4000|\n",
      "|  4|    Maria|      Anne|   Jones| 36|         9|      Java| Hyderabad|           4|1967-12-01 00:00:...|     F|  5000|\n",
      "|  5|      Jen|      Mary|   Brown| 39|         5|     Scala|    Nagpur|           5|1980-02-17 00:00:...|     F|     0|\n",
      "|  6|Prabhakar|         B|       G| 33|        11|    Python|      Pune|           2|1967-12-01 00:00:...|     M|  5000|\n",
      "|  7|  Praveen|         B|       G| 21|        13|      Java| Hyderabad|           3|1967-12-01 00:00:...|     M|  6500|\n",
      "|  8|   Rajesh|         B|       G| 25|         2|     Scala|   Nellore|           4|1967-12-01 00:00:...|     M|  5100|\n",
      "|  9|  Pramodh|         B|       G| 49|         9|      Ruby|      Pune|           1|1967-12-01 00:00:...|     M|  5000|\n",
      "| 10|     Ajay|      None|    None| 50|        10|      None|      Pune|           5|1967-12-01 00:00:...|     M|  2500|\n",
      "| 11|      Bob|         D|    None| 43|        14|         R| Hyderabad|           6|1967-12-01 00:00:...|     M|  2500|\n",
      "| 12|    Chris|         B|   Smith| 47|        12|JavaScript|      None|           6|1967-12-01 00:00:...|     M|  2500|\n",
      "+---+---------+----------+--------+---+----------+----------+----------+------------+--------------------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703c41ce",
   "metadata": {},
   "source": [
    "### Convert dataframe to SQL object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7326126",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('personal_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5bef8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_df = spark.sql(\"select * from personal_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef92d7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------+--------+---+----------+----------+----------+------------+--------------------+------+------+\n",
      "| SN|firstname|middlename|lastname|age|experiance|     skill|      city|departmentID|                 DOB|gender|salary|\n",
      "+---+---------+----------+--------+---+----------+----------+----------+------------+--------------------+------+------+\n",
      "|  1|    James|        Kc|   Smith| 51|        10|      .Net|   Newyork|           1|1991-04-01 00:00:...|     M|  3000|\n",
      "|  2|  Michael|      Rose|    None| 45|        11|      Ruby|   Newyork|           2|2000-05-19 00:00:...|     M|  4000|\n",
      "|  3|   Robert|      None|Williams| 32|        10|     Scala|California|           1|1978-09-05 00:00:...|     M|  4000|\n",
      "|  4|    Maria|      Anne|   Jones| 36|         9|      Java| Hyderabad|           4|1967-12-01 00:00:...|     F|  5000|\n",
      "|  5|      Jen|      Mary|   Brown| 39|         5|     Scala|    Nagpur|           5|1980-02-17 00:00:...|     F|     0|\n",
      "|  6|Prabhakar|         B|       G| 33|        11|    Python|      Pune|           2|1967-12-01 00:00:...|     M|  5000|\n",
      "|  7|  Praveen|         B|       G| 21|        13|      Java| Hyderabad|           3|1967-12-01 00:00:...|     M|  6500|\n",
      "|  8|   Rajesh|         B|       G| 25|         2|     Scala|   Nellore|           4|1967-12-01 00:00:...|     M|  5100|\n",
      "|  9|  Pramodh|         B|       G| 49|         9|      Ruby|      Pune|           1|1967-12-01 00:00:...|     M|  5000|\n",
      "| 10|     Ajay|      None|    None| 50|        10|      None|      Pune|           5|1967-12-01 00:00:...|     M|  2500|\n",
      "| 11|      Bob|         D|    None| 43|        14|         R| Hyderabad|           6|1967-12-01 00:00:...|     M|  2500|\n",
      "| 12|    Chris|         B|   Smith| 47|        12|JavaScript|      None|           6|1967-12-01 00:00:...|     M|  2500|\n",
      "+---+---------+----------+--------+---+----------+----------+----------+------------+--------------------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "select_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8b1bac",
   "metadata": {},
   "source": [
    "### Using group by on the departmentID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "943fb983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+----------+--------+\n",
      "|departmentID|      city|experiance|count(1)|\n",
      "+------------+----------+----------+--------+\n",
      "|           2|      Pune|        11|       1|\n",
      "|           1|      Pune|         9|       1|\n",
      "|           5|      Pune|        10|       1|\n",
      "|           6|      None|        12|       1|\n",
      "|           1|   Newyork|        10|       1|\n",
      "|           2|   Newyork|        11|       1|\n",
      "|           4|   Nellore|         2|       1|\n",
      "|           5|    Nagpur|         5|       1|\n",
      "|           3| Hyderabad|        13|       1|\n",
      "|           4| Hyderabad|         9|       1|\n",
      "|           6| Hyderabad|        14|       1|\n",
      "|           1|California|        10|       1|\n",
      "+------------+----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "groupBY_df = spark.sql(\"select departmentID, city, experiance, count(*) from personal_data group by departmentID, city,experiance order by city desc\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68619fd9",
   "metadata": {},
   "source": [
    "### Using group by on city column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c84580e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|      city|count(1)|\n",
      "+----------+--------+\n",
      "|      Pune|       3|\n",
      "| Hyderabad|       3|\n",
      "|   Newyork|       2|\n",
      "|      None|       1|\n",
      "|   Nellore|       1|\n",
      "|    Nagpur|       1|\n",
      "|California|       1|\n",
      "+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "city_groupBY_df = spark.sql(\"select city, count(*) from personal_data group by city order by count(1) desc\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1963b3",
   "metadata": {},
   "source": [
    "### Grouping the data on the basis of skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e235a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|     skill|count(1)|\n",
      "+----------+--------+\n",
      "|JavaScript|       1|\n",
      "|    Python|       1|\n",
      "|         R|       1|\n",
      "|      .Net|       1|\n",
      "|      None|       1|\n",
      "|      Ruby|       2|\n",
      "|      Java|       2|\n",
      "|     Scala|       3|\n",
      "+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "city_df = spark.sql(\"select skill, count(*) from personal_data group by skill order by count(1) asc\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e686fc75",
   "metadata": {},
   "source": [
    "### Using wildcard in SparkSQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5ab264b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------+--------+---+----------+------+----------+------------+--------------------+------+------+\n",
      "| SN|firstname|middlename|lastname|age|experiance| skill|      city|departmentID|                 DOB|gender|salary|\n",
      "+---+---------+----------+--------+---+----------+------+----------+------------+--------------------+------+------+\n",
      "|  3|   Robert|      None|Williams| 32|        10| Scala|California|           1|1978-09-05 00:00:...|     M|  4000|\n",
      "|  6|Prabhakar|         B|       G| 33|        11|Python|      Pune|           2|1967-12-01 00:00:...|     M|  5000|\n",
      "| 11|      Bob|         D|    None| 43|        14|     R| Hyderabad|           6|1967-12-01 00:00:...|     M|  2500|\n",
      "+---+---------+----------+--------+---+----------+------+----------+------------+--------------------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wildcard_p_df = spark.sql(\"select * from personal_data where firstname LIKE '%b%'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692e1b53",
   "metadata": {},
   "source": [
    "### Using the filter condition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dfedbc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------+--------+---+----------+----------+----------+------------+--------------------+------+------+\n",
      "| SN|firstname|middlename|lastname|age|experiance|     skill|      city|departmentID|                 DOB|gender|salary|\n",
      "+---+---------+----------+--------+---+----------+----------+----------+------------+--------------------+------+------+\n",
      "|  7|  Praveen|         B|       G| 21|        13|      Java| Hyderabad|           3|1967-12-01 00:00:...|     M|  6500|\n",
      "|  8|   Rajesh|         B|       G| 25|         2|     Scala|   Nellore|           4|1967-12-01 00:00:...|     M|  5100|\n",
      "|  6|Prabhakar|         B|       G| 33|        11|    Python|      Pune|           2|1967-12-01 00:00:...|     M|  5000|\n",
      "|  9|  Pramodh|         B|       G| 49|         9|      Ruby|      Pune|           1|1967-12-01 00:00:...|     M|  5000|\n",
      "|  2|  Michael|      Rose|    None| 45|        11|      Ruby|   Newyork|           2|2000-05-19 00:00:...|     M|  4000|\n",
      "|  3|   Robert|      None|Williams| 32|        10|     Scala|California|           1|1978-09-05 00:00:...|     M|  4000|\n",
      "|  1|    James|        Kc|   Smith| 51|        10|      .Net|   Newyork|           1|1991-04-01 00:00:...|     M|  3000|\n",
      "| 10|     Ajay|      None|    None| 50|        10|      None|      Pune|           5|1967-12-01 00:00:...|     M|  2500|\n",
      "| 11|      Bob|         D|    None| 43|        14|         R| Hyderabad|           6|1967-12-01 00:00:...|     M|  2500|\n",
      "| 12|    Chris|         B|   Smith| 47|        12|JavaScript|      None|           6|1967-12-01 00:00:...|     M|  2500|\n",
      "+---+---------+----------+--------+---+----------+----------+----------+------------+--------------------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filter_df = spark.sql(\"select * from personal_data where gender == 'M' order by salary desc\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e90ca214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------+--------+---+----------+-----+---------+------------+--------------------+------+------+\n",
      "| SN|firstname|middlename|lastname|age|experiance|skill|     city|departmentID|                 DOB|gender|salary|\n",
      "+---+---------+----------+--------+---+----------+-----+---------+------------+--------------------+------+------+\n",
      "|  4|    Maria|      Anne|   Jones| 36|         9| Java|Hyderabad|           4|1967-12-01 00:00:...|     F|  5000|\n",
      "|  5|      Jen|      Mary|   Brown| 39|         5|Scala|   Nagpur|           5|1980-02-17 00:00:...|     F|     0|\n",
      "+---+---------+----------+--------+---+----------+-----+---------+------------+--------------------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filter1_df = spark.sql(\"select * from personal_data where gender != 'M' order by salary desc\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bcfca97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------+--------+---+----------+----------+----------+------------+--------------------+------+------+\n",
      "| SN|firstname|middlename|lastname|age|experiance|     skill|      city|departmentID|                 DOB|gender|salary|\n",
      "+---+---------+----------+--------+---+----------+----------+----------+------------+--------------------+------+------+\n",
      "|  7|  Praveen|         B|       G| 21|        13|      Java| Hyderabad|           3|1967-12-01 00:00:...|     M|  6500|\n",
      "|  8|   Rajesh|         B|       G| 25|         2|     Scala|   Nellore|           4|1967-12-01 00:00:...|     M|  5100|\n",
      "|  6|Prabhakar|         B|       G| 33|        11|    Python|      Pune|           2|1967-12-01 00:00:...|     M|  5000|\n",
      "|  9|  Pramodh|         B|       G| 49|         9|      Ruby|      Pune|           1|1967-12-01 00:00:...|     M|  5000|\n",
      "|  2|  Michael|      Rose|    None| 45|        11|      Ruby|   Newyork|           2|2000-05-19 00:00:...|     M|  4000|\n",
      "|  3|   Robert|      None|Williams| 32|        10|     Scala|California|           1|1978-09-05 00:00:...|     M|  4000|\n",
      "|  1|    James|        Kc|   Smith| 51|        10|      .Net|   Newyork|           1|1991-04-01 00:00:...|     M|  3000|\n",
      "| 10|     Ajay|      None|    None| 50|        10|      None|      Pune|           5|1967-12-01 00:00:...|     M|  2500|\n",
      "| 11|      Bob|         D|    None| 43|        14|         R| Hyderabad|           6|1967-12-01 00:00:...|     M|  2500|\n",
      "| 12|    Chris|         B|   Smith| 47|        12|JavaScript|      None|           6|1967-12-01 00:00:...|     M|  2500|\n",
      "+---+---------+----------+--------+---+----------+----------+----------+------------+--------------------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filter1_df = spark.sql(\"select * from personal_data where gender != 'F' order by salary desc\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dade48d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------+--------+---+----------+-----+---------+------------+--------------------+------+------+\n",
      "| SN|firstname|middlename|lastname|age|experiance|skill|     city|departmentID|                 DOB|gender|salary|\n",
      "+---+---------+----------+--------+---+----------+-----+---------+------------+--------------------+------+------+\n",
      "|  4|    Maria|      Anne|   Jones| 36|         9| Java|Hyderabad|           4|1967-12-01 00:00:...|     F|  5000|\n",
      "|  5|      Jen|      Mary|   Brown| 39|         5|Scala|   Nagpur|           5|1980-02-17 00:00:...|     F|     0|\n",
      "+---+---------+----------+--------+---+----------+-----+---------+------------+--------------------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filter1_df = spark.sql(\"select * from personal_data where gender == 'F' order by salary desc\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "746c7c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------+--------+---+----------+------+---------+------------+--------------------+------+------+\n",
      "| SN|firstname|middlename|lastname|age|experiance| skill|     city|departmentID|                 DOB|gender|salary|\n",
      "+---+---------+----------+--------+---+----------+------+---------+------------+--------------------+------+------+\n",
      "|  4|    Maria|      Anne|   Jones| 36|         9|  Java|Hyderabad|           4|1967-12-01 00:00:...|     F|  5000|\n",
      "|  6|Prabhakar|         B|       G| 33|        11|Python|     Pune|           2|1967-12-01 00:00:...|     M|  5000|\n",
      "|  7|  Praveen|         B|       G| 21|        13|  Java|Hyderabad|           3|1967-12-01 00:00:...|     M|  6500|\n",
      "|  8|   Rajesh|         B|       G| 25|         2| Scala|  Nellore|           4|1967-12-01 00:00:...|     M|  5100|\n",
      "|  9|  Pramodh|         B|       G| 49|         9|  Ruby|     Pune|           1|1967-12-01 00:00:...|     M|  5000|\n",
      "+---+---------+----------+--------+---+----------+------+---------+------------+--------------------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filter2_df = spark.sql(\"select * from personal_data where salary > 4000\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3d44cf",
   "metadata": {},
   "source": [
    "### Using rank function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "67baf5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------+--------+---+----------+----------+----------+------------+--------------------+------+------+---+\n",
      "| SN|firstname|middlename|lastname|age|experiance|     skill|      city|departmentID|                 DOB|gender|salary|rnk|\n",
      "+---+---------+----------+--------+---+----------+----------+----------+------------+--------------------+------+------+---+\n",
      "|  7|  Praveen|         B|       G| 21|        13|      Java| Hyderabad|           3|1967-12-01 00:00:...|     M|  6500|  1|\n",
      "| 10|     Ajay|      None|    None| 50|        10|      None|      Pune|           5|1967-12-01 00:00:...|     M|  2500|  1|\n",
      "|  5|      Jen|      Mary|   Brown| 39|         5|     Scala|    Nagpur|           5|1980-02-17 00:00:...|     F|     0|  2|\n",
      "| 11|      Bob|         D|    None| 43|        14|         R| Hyderabad|           6|1967-12-01 00:00:...|     M|  2500|  1|\n",
      "| 12|    Chris|         B|   Smith| 47|        12|JavaScript|      None|           6|1967-12-01 00:00:...|     M|  2500|  1|\n",
      "|  9|  Pramodh|         B|       G| 49|         9|      Ruby|      Pune|           1|1967-12-01 00:00:...|     M|  5000|  1|\n",
      "|  3|   Robert|      None|Williams| 32|        10|     Scala|California|           1|1978-09-05 00:00:...|     M|  4000|  2|\n",
      "|  8|   Rajesh|         B|       G| 25|         2|     Scala|   Nellore|           4|1967-12-01 00:00:...|     M|  5100|  1|\n",
      "|  4|    Maria|      Anne|   Jones| 36|         9|      Java| Hyderabad|           4|1967-12-01 00:00:...|     F|  5000|  2|\n",
      "|  6|Prabhakar|         B|       G| 33|        11|    Python|      Pune|           2|1967-12-01 00:00:...|     M|  5000|  1|\n",
      "|  2|  Michael|      Rose|    None| 45|        11|      Ruby|   Newyork|           2|2000-05-19 00:00:...|     M|  4000|  2|\n",
      "+---+---------+----------+--------+---+----------+----------+----------+------------+--------------------+------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rank_df = spark.sql(\"\"\"\n",
    "    SELECT *,\n",
    "           RANK() OVER (PARTITION BY departmentID ORDER BY salary DESC) AS rnk\n",
    "    FROM personal_data\n",
    "\"\"\") \n",
    "rank_df = rank_df.filter(rank_df.rnk < 3)\n",
    "rank_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dc26029c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------+--------+---+----------+----------+----------+------------+--------------------+------+------+---+\n",
      "| SN|firstname|middlename|lastname|age|experiance|     skill|      city|departmentID|                 DOB|gender|salary|rnk|\n",
      "+---+---------+----------+--------+---+----------+----------+----------+------------+--------------------+------+------+---+\n",
      "|  7|  Praveen|         B|       G| 21|        13|      Java| Hyderabad|           3|1967-12-01 00:00:...|     M|  6500|  1|\n",
      "| 10|     Ajay|      None|    None| 50|        10|      None|      Pune|           5|1967-12-01 00:00:...|     M|  2500|  1|\n",
      "|  5|      Jen|      Mary|   Brown| 39|         5|     Scala|    Nagpur|           5|1980-02-17 00:00:...|     F|     0|  2|\n",
      "| 11|      Bob|         D|    None| 43|        14|         R| Hyderabad|           6|1967-12-01 00:00:...|     M|  2500|  1|\n",
      "| 12|    Chris|         B|   Smith| 47|        12|JavaScript|      None|           6|1967-12-01 00:00:...|     M|  2500|  1|\n",
      "|  9|  Pramodh|         B|       G| 49|         9|      Ruby|      Pune|           1|1967-12-01 00:00:...|     M|  5000|  1|\n",
      "|  3|   Robert|      None|Williams| 32|        10|     Scala|California|           1|1978-09-05 00:00:...|     M|  4000|  2|\n",
      "|  8|   Rajesh|         B|       G| 25|         2|     Scala|   Nellore|           4|1967-12-01 00:00:...|     M|  5100|  1|\n",
      "|  4|    Maria|      Anne|   Jones| 36|         9|      Java| Hyderabad|           4|1967-12-01 00:00:...|     F|  5000|  2|\n",
      "|  6|Prabhakar|         B|       G| 33|        11|    Python|      Pune|           2|1967-12-01 00:00:...|     M|  5000|  1|\n",
      "|  2|  Michael|      Rose|    None| 45|        11|      Ruby|   Newyork|           2|2000-05-19 00:00:...|     M|  4000|  2|\n",
      "+---+---------+----------+--------+---+----------+----------+----------+------------+--------------------+------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rank_df = spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM (\n",
    "        SELECT *,\n",
    "               RANK() OVER (PARTITION BY departmentID ORDER BY salary DESC) AS rnk\n",
    "        FROM personal_data\n",
    "    ) x\n",
    "    WHERE x.rnk < 3\n",
    "\"\"\")\n",
    "rank_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf03f32d",
   "metadata": {},
   "source": [
    "### Using Dense Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "60cf76f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------+--------+---+----------+----------+---------+------------+--------------------+------+------+---+\n",
      "| SN|firstname|middlename|lastname|age|experiance|     skill|     city|departmentID|                 DOB|gender|salary|dnk|\n",
      "+---+---------+----------+--------+---+----------+----------+---------+------------+--------------------+------+------+---+\n",
      "|  7|  Praveen|         B|       G| 21|        13|      Java|Hyderabad|           3|1967-12-01 00:00:...|     M|  6500|  1|\n",
      "| 10|     Ajay|      None|    None| 50|        10|      None|     Pune|           5|1967-12-01 00:00:...|     M|  2500|  1|\n",
      "| 11|      Bob|         D|    None| 43|        14|         R|Hyderabad|           6|1967-12-01 00:00:...|     M|  2500|  1|\n",
      "| 12|    Chris|         B|   Smith| 47|        12|JavaScript|     None|           6|1967-12-01 00:00:...|     M|  2500|  1|\n",
      "|  9|  Pramodh|         B|       G| 49|         9|      Ruby|     Pune|           1|1967-12-01 00:00:...|     M|  5000|  1|\n",
      "|  8|   Rajesh|         B|       G| 25|         2|     Scala|  Nellore|           4|1967-12-01 00:00:...|     M|  5100|  1|\n",
      "|  6|Prabhakar|         B|       G| 33|        11|    Python|     Pune|           2|1967-12-01 00:00:...|     M|  5000|  1|\n",
      "+---+---------+----------+--------+---+----------+----------+---------+------------+--------------------+------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dense_rnk_df = spark.sql(\"\"\"\n",
    "    SELECT * FROM (\n",
    "        select *,\n",
    "        DENSE_RANK() over(partition by departmentID order by salary desc) as dnk\n",
    "        from personal_data\n",
    "        )x\n",
    "        where x.dnk =1\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d336b5c2",
   "metadata": {},
   "source": [
    "### Using ROW_NUMBER()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "78f9211f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------+--------+---+----------+-----+---------+------------+--------------------+------+------+---+\n",
      "| SN|firstname|middlename|lastname|age|experiance|skill|     city|departmentID|                 DOB|gender|salary| rn|\n",
      "+---+---------+----------+--------+---+----------+-----+---------+------------+--------------------+------+------+---+\n",
      "|  7|  Praveen|         B|       G| 21|        13| Java|Hyderabad|           3|1967-12-01 00:00:...|     M|  6500|  1|\n",
      "|  5|      Jen|      Mary|   Brown| 39|         5|Scala|   Nagpur|           5|1980-02-17 00:00:...|     F|     0|  1|\n",
      "| 11|      Bob|         D|    None| 43|        14|    R|Hyderabad|           6|1967-12-01 00:00:...|     M|  2500|  1|\n",
      "|  1|    James|        Kc|   Smith| 51|        10| .Net|  Newyork|           1|1991-04-01 00:00:...|     M|  3000|  1|\n",
      "|  4|    Maria|      Anne|   Jones| 36|         9| Java|Hyderabad|           4|1967-12-01 00:00:...|     F|  5000|  1|\n",
      "|  2|  Michael|      Rose|    None| 45|        11| Ruby|  Newyork|           2|2000-05-19 00:00:...|     M|  4000|  1|\n",
      "+---+---------+----------+--------+---+----------+-----+---------+------------+--------------------+------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rownm_df = spark.sql(\"\"\"\n",
    "    SELECT * FROM (SELECT *,\n",
    "        ROW_NUMBER() OVER(partition by departmentID order by salary asc) as rn\n",
    "        FROM personal_data)x\n",
    "    where x.rn =1\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b052568",
   "metadata": {},
   "source": [
    "### Using max function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a81bd756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "|departmentID|max(salary)|\n",
      "+------------+-----------+\n",
      "|           3|       6500|\n",
      "|           4|       5100|\n",
      "|           1|       5000|\n",
      "|           2|       5000|\n",
      "|           5|       2500|\n",
      "|           6|       2500|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_df = spark.sql(\"\"\"\n",
    "    SELECT departmentID, max(salary) from personal_data group by departmentID order by max(salary) desc\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c13bc0",
   "metadata": {},
   "source": [
    "### Avg salary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1dc5d2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|departmentID|avg_salary|\n",
      "+------------+----------+\n",
      "|           3|    6500.0|\n",
      "|           4|    5050.0|\n",
      "|           2|    4500.0|\n",
      "|           1|    4000.0|\n",
      "|           6|    2500.0|\n",
      "|           5|    1250.0|\n",
      "+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agg_df = spark.sql(\"\"\"\n",
    "    SELECT departmentID, AVG(salary) AS avg_salary\n",
    "    FROM personal_data\n",
    "    GROUP BY departmentID\n",
    "    ORDER BY avg_salary desc\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3738aa27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
